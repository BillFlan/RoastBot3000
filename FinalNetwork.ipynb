{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "ibuG0inxLHuS",
    "outputId": "b4794d0c-674e-4946-9386-f6ad47b8664a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "! pip install -q -U trax\n",
    "! pip install -q tensorflow\n",
    "import trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxCgxFIhLRIy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import numpy as onp\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "26-qJXF51Bau",
    "outputId": "9f39b000-8880-424d-fe0f-c4a0582a3b6e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGvBYXlQAPlE"
   },
   "outputs": [],
   "source": [
    "PATH = PATH = os.path.abspath('./drive/My Drive/Final Project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEdo3HA1wWBD"
   },
   "outputs": [],
   "source": [
    "#copy zip to disk\n",
    "shutil.copyfile(PATH+'/resizedFinals.zip', './resizedFinals.zip')\n",
    "#extract\n",
    "with ZipFile('./resizedFinals.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall()\n",
    "#remove unzipping bits\n",
    "shutil.rmtree('./__MACOSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iu4dXRep1rvF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPWA52WwUYfI"
   },
   "outputs": [],
   "source": [
    "#copy zip to disk\n",
    "shutil.copyfile(PATH+'/cachedImages.zip', './cachedImages.zip')\n",
    "#extract\n",
    "with ZipFile('./cachedImages.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUo3-nw-UqWr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CdrmuDc6oI1"
   },
   "outputs": [],
   "source": [
    "#run this\n",
    "PATH = os.path.abspath('./resizedFinals')\n",
    "caption_file = os.path.abspath(PATH+'/textFiles/comment_list.json')\n",
    "\n",
    "with open(caption_file, 'r') as f:\n",
    "    comments = json.load(f)\n",
    "\n",
    "# Store comments and image names in vectors\n",
    "all_captions = []\n",
    "all_img_name_vector = []\n",
    "MAX_SIZE = 64\n",
    "\n",
    "for c in comments:\n",
    "    comment = '<start> ' + c['body'] + ' <end>'\n",
    "    if len(comment.split(' ')) > MAX_SIZE:\n",
    "      continue\n",
    "    image_id = c['id']\n",
    "    full_image_path = PATH + '/resized/' + image_id + '.jpg'\n",
    "\n",
    "    all_img_name_vector.append(full_image_path)\n",
    "    all_captions.append(comment)\n",
    "\n",
    "\n",
    "# Shuffle captions and image_names together\n",
    "# Set a random state\n",
    "train_captions, img_name_vector = shuffle(all_captions,\n",
    "                                          all_img_name_vector,\n",
    "                                          random_state=1)\n",
    "\n",
    "# Select the first 30000 captions from the shuffled set\n",
    "num_examples = 30000\n",
    "train_captions = train_captions[:num_examples]\n",
    "img_name_vector = img_name_vector[:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ga73rftLJOnl",
    "outputId": "d0f05ebc-492b-46ac-9c7e-3e27d0c0c147"
   },
   "outputs": [],
   "source": [
    "len(train_captions), len(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB71R5d_MCnn"
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Fu6HVazUMU2z",
    "outputId": "58a1fe00-ed4c-4167-c4e6-742f81561bd0"
   },
   "outputs": [],
   "source": [
    "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DaFYksN0dHKC",
    "outputId": "53011127-d6c3-4cee-a1f7-1650b0d86f95"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kc9IaV2JPmGU"
   },
   "outputs": [],
   "source": [
    "!pip install -q tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NNkcVeYGS9U3",
    "outputId": "01833994-7e83-464d-c7e7-9b7a1fcfa137"
   },
   "outputs": [],
   "source": [
    "len(sorted(set(img_name_vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "id": "9j6xsS9BMie7",
    "outputId": "9461d884-7375-4651-c687-7beb8629fb16"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH+'/carp/'):\n",
    "  os.makedirs(os.path.abspath(PATH+'/carp/'))\n",
    "# Get unique images\n",
    "encode_train = sorted(set(img_name_vector))\n",
    "# Feel free to change batch_size according to your system configuration\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
    "image_dataset = image_dataset.map(\n",
    "  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
    "\n",
    "for img, path in image_dataset:\n",
    "  print(img.shape)\n",
    "  batch_features = image_features_extract_model(img)\n",
    "  print(batch_features.shape)\n",
    "  batch_features = tf.reshape(batch_features,\n",
    "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "  print(batch_features.shape)\n",
    "  print()\n",
    "\n",
    "  for bf, p in zip(batch_features, path):\n",
    "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
    "    path_of_feature = path_of_feature.split('/')\n",
    "    path_of_feature[-2] = 'carp'\n",
    "    path_of_feature = '/'.join(path_of_feature)\n",
    "    np.save(path_of_feature, bf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ng24pISiM9zV",
    "outputId": "89c95229-79d6-4f17-ba97-a6fbe2cf9e41"
   },
   "outputs": [],
   "source": [
    "#takes about 10 minutes\n",
    "shutil.make_archive('./cachedImages','zip',base_dir='./resizedFinals/cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vUe2S_7FVUAX",
    "outputId": "75f01daa-67a9-450f-c785-b37729f2ac1d"
   },
   "outputs": [],
   "source": [
    "shutil.copyfile('./cachedImages.zip', './drive/My Drive/Final Project/cachedImages.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "52MMpIpYcH9n"
   },
   "outputs": [],
   "source": [
    "# Find the maximum length of any caption in our dataset\n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "# Choose the top 5000 words from the vocabulary\n",
    "top_k = 5000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(train_captions)\n",
    "train_seqs = tokenizer.texts_to_sequences(train_captions)\n",
    "\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# Create the tokenized vectors\n",
    "train_seqs = tokenizer.texts_to_sequences(train_captions)\n",
    "\n",
    "# Pad each vector to the max_length of the captions\n",
    "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post', maxlen=MAX_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ubTG2DkmOe2E",
    "outputId": "5ea61575-15fd-42dd-b889-566f5a9ba000"
   },
   "outputs": [],
   "source": [
    "print(len(cap_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEYcROLQe_Ic"
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(img_name_vector):\n",
    "  name = name.split('/')\n",
    "  name[-2] = 'cached'\n",
    "  img_name_vector[i] = '/'.join(name)\n",
    "# Create training and validation sets using an 80-20 split\n",
    "img_name_train, img_name_val, cap_train, cap_val= train_test_split(img_name_vector,\n",
    "                                                                    cap_vector,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "43q0u4wrfAg6",
    "outputId": "3efb2029-7960-497b-9372-8b5048392f5d"
   },
   "outputs": [],
   "source": [
    "len(img_name_train), len(cap_train), len(img_name_val), len(cap_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NlCpN2YEeYMj"
   },
   "outputs": [],
   "source": [
    "# Feel free to change these parameters according to your system's configuration\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "embedding_dim = 256\n",
    "vocab_size = top_k + 1\n",
    "num_steps = len(img_name_train) // BATCH_SIZE\n",
    "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
    "# These two variables represent that vector shape\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7yLyFJ3eaEg"
   },
   "outputs": [],
   "source": [
    "# Load the numpy files\n",
    "def map_func(img_name, cap):\n",
    "  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
    "  return img_tensor, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ag4OuJ55ecVu"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n",
    "#Use map to load the numpy files in parallel\n",
    "dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# Shuffle and batch\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtcfqIpDee5F"
   },
   "outputs": [],
   "source": [
    "from trax.supervised import inputs\n",
    "from trax import math\n",
    "from trax import layers as tl\n",
    "from trax.models import reformer as rf\n",
    "from trax.shapes import ShapeDtype\n",
    "from trax.shapes import signature\n",
    "import jax\n",
    "import jax.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8_oU9oQ7q-S"
   },
   "outputs": [],
   "source": [
    "def map_func(img_name):\n",
    "  img_tensor = np.load(img_name+'.npy')\n",
    "  return img_tensor\n",
    "\n",
    "def my_input(n_devices, img_name_list, cap_list):\n",
    "  spot = 0\n",
    "  while spot < len(img_name_list):\n",
    "    spot += n_devices\n",
    "    yield (np.array(list(map(map_func, img_name_list[spot:spot+n_devices]))), \n",
    "          cap_list[spot:spot+n_devices])\n",
    "\n",
    "inputTest = my_input(1, img_name_train, cap_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "aHYA_pZue8fr",
    "outputId": "9ceee578-b5f3-4da8-b977-49b39a703345"
   },
   "outputs": [],
   "source": [
    "roast_inputs = trax.supervised.Inputs(lambda n_devices: my_input(n_devices, img_name_train, cap_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_qdL1_9V5o8"
   },
   "outputs": [],
   "source": [
    "import trax.models.transformer as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "IL3ClvjVVweP",
    "outputId": "9d8ec169-6f72-4970-f448-0a5aa2b3ebbf"
   },
   "outputs": [],
   "source": [
    "def complicated2(input_vocab_size,\n",
    "                output_vocab_size=None,\n",
    "                d_model=512,\n",
    "                d_ff=2048,\n",
    "                n_encoder_layers=6,\n",
    "                n_decoder_layers=6,\n",
    "                n_heads=8,\n",
    "                dropout=0.1,\n",
    "                max_len=2048,\n",
    "                mode='train',\n",
    "                ff_activation=tl.Relu):\n",
    "  \"\"\"Returns a Transformer model.\n",
    "  This model expects an input pair: target, source.\n",
    "  Args:\n",
    "    input_vocab_size: int: vocab size of the source.\n",
    "    output_vocab_size: int (optional): vocab size of the target. If None, the\n",
    "      source and target are assumed to have the same vocab.\n",
    "    d_model: int:  depth of embedding\n",
    "    d_ff: int: depth of feed-forward layer\n",
    "    n_encoder_layers: int: number of encoder layers\n",
    "    n_decoder_layers: int: number of decoder layers\n",
    "    n_heads: int: number of attention heads\n",
    "    dropout: float: dropout rate (how much to drop out)\n",
    "    max_len: int: maximum symbol length for positional encoding\n",
    "    mode: str: 'train' or 'eval'\n",
    "    ff_activation: the non-linearity in feed-forward layer\n",
    "  Returns:\n",
    "    A Transformer model as a layer that maps from a target, source pair to\n",
    "    activations over a vocab set.\n",
    "  \"\"\"\n",
    "  def PositionalEncoder(vocab_size):  # tokens --> vectors\n",
    "    return [\n",
    "        tl.Embedding(d_model, vocab_size),\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        tl.PositionalEncoding(max_len=max_len),\n",
    "    ]\n",
    "\n",
    "  in_encoder = PositionalEncoder(input_vocab_size)\n",
    "  out_encoder = (in_encoder if output_vocab_size is None\n",
    "                 else PositionalEncoder(output_vocab_size))\n",
    "  if output_vocab_size is None:\n",
    "    output_vocab_size = input_vocab_size\n",
    "\n",
    "  encoder_blocks = [\n",
    "      tr._EncoderBlock(\n",
    "          d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n",
    "      for i in range(n_encoder_layers)]\n",
    "\n",
    "  #change to use rnn data\n",
    "  encoder = tl.Serial(\n",
    "      tl.Dense(d_model),\n",
    "      tl.Relu()\n",
    "  )\n",
    "  # encoder = tl.Serial(\n",
    "  #     in_encoder,\n",
    "  #     encoder_blocks,\n",
    "  #     tl.LayerNorm()\n",
    "  # )\n",
    "  if mode == 'predict':\n",
    "    encoder = tl.Cache(encoder)\n",
    "\n",
    "  encoder_decoder_blocks = [\n",
    "      tr._EncoderDecoderBlock(\n",
    "          d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n",
    "      for i in range(n_decoder_layers)]\n",
    "\n",
    "  # Assemble and return the model.\n",
    "  return tl.Serial(\n",
    "      # Input: encoder_side_tokens, decoder_side_tokens\n",
    "      # Copy decoder tokens for use in loss.\n",
    "      tl.Select([1, 0, 1]),               # tok_e tok_d tok_d\n",
    "\n",
    "      # Encode.\n",
    "      tl.Branch([], tl.PaddingMask()),    # tok_d masks ..... .....\n",
    "      tl.Select([2, 1, 0]),               # tok_e masks tok_d .....\n",
    "      encoder,                            # vec_e ..... ..... .....\n",
    "\n",
    "      # # Decode.\n",
    "      tl.Select([2, 1, 0]),               # tok_d masks vec_e .....\n",
    "      tl.ShiftRight(),                    # tok_d ..... ..... .....\n",
    "      out_encoder,                        # vec_d ..... ..... .....\n",
    "      tl.Branch(\n",
    "          [], tl.EncoderDecoderMask()),   # vec_d masks ..... .....\n",
    "      encoder_decoder_blocks,             # vec_d masks ..... .....\n",
    "      tl.LayerNorm(),                     # vec_d ..... ..... .....\n",
    "\n",
    "      # Map to output vocab.\n",
    "      tl.Select([0], n_in=3),             # vec_d tok_d\n",
    "      tl.Dense(output_vocab_size),        # vec_d .....\n",
    "      tl.LogSoftmax(),                    # vec_d .....\n",
    "  )\n",
    "test = complicated2(input_vocab_size=vocab_size, mode='train')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BhJVMmJT6i1c",
    "outputId": "2b88328c-7f57-4bcb-a269-0a69b99d1dfd"
   },
   "outputs": [],
   "source": [
    "inputTest = my_input(3, img_name_train, cap_train)\n",
    "coolGuy1 = next(inputTest)\n",
    "coolGuy2 = next(inputTest)\n",
    "guyLength = -1\n",
    "testGuy = (coolGuy1[0], coolGuy1[1])\n",
    "test.init(signature(coolGuy1))\n",
    "signature(coolGuy1)\n",
    "\n",
    "# testGuyOldSkool = (coolGuy1[1][:,1:guyLength], coolGuy2[1][:,1:guyLength])\n",
    "# test.init(signature(testGuyOldSkool))\n",
    "# signature(testGuyOldSkool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VQJvdBB7YCVQ",
    "outputId": "56c7de5b-12a4-4840-dba6-52e0de5bdaef"
   },
   "outputs": [],
   "source": [
    "runIt = test(coolGuy1)\n",
    "signature(runIt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eMgwxc_6QNP"
   },
   "outputs": [],
   "source": [
    "def LotsOfEffort(mode):\n",
    "  return complicated2(vocab_size, d_model=embedding_dim, d_ff=1024, max_len=MAX_SIZE, mode=mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z64cHxXBpxxd"
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.abspath('./drive/My Drive/Final Project/train_dir/')\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eV0UB3Dsr3Vb",
    "outputId": "72ab7675-20f7-4ffd-f3d7-648b388245b7"
   },
   "outputs": [],
   "source": [
    "roast_inputs = trax.supervised.Inputs(lambda n_devices: my_input(n_devices, img_name_train, cap_train))\n",
    "roast_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xh9nmS36TLc"
   },
   "outputs": [],
   "source": [
    "# Train tiny model with Trainer.\n",
    "output_dir = os.path.abspath('./drive/My Drive/Final Project/train_dir/')\n",
    "!rm -f ./train_dir/model.pkl  # Remove old model.\n",
    "trainer = trax.supervised.Trainer(\n",
    "    model=LotsOfEffort,\n",
    "    loss_fn=trax.layers.CrossEntropyLoss(),\n",
    "    optimizer=trax.optimizers.Adafactor,  # Change optimizer params here.\n",
    "    lr_schedule=trax.lr.MultifactorSchedule,  # Change lr schedule here.\n",
    "    inputs=roast_inputs,\n",
    "    output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ibwsSOICtOrQ",
    "outputId": "bb2db25b-68bd-4528-897f-da49338ba68f"
   },
   "outputs": [],
   "source": [
    "# Train for 3 epochs each consisting of 500 train batches, eval on 2 batches.\n",
    "n_epochs  = 20\n",
    "train_steps = num_steps\n",
    "eval_steps = 2\n",
    "for _ in range(n_epochs):\n",
    "  trainer.train_epoch(train_steps, eval_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ix5M7Y7nmcUQ"
   },
   "outputs": [],
   "source": [
    "# Initialize model for inference.\n",
    "output_dir = os.path.abspath('./drive/My Drive/Final Project/train_dir/')\n",
    "predict_model = LotsOfEffort(mode='predict')\n",
    "\n",
    "predict_signature = (trax.shapes.ShapeDtype((1, 64, 2048), dtype=np.float32), ShapeDtype((1, 1), dtype=np.int32))\n",
    "\n",
    "predict_model.init(predict_signature)\n",
    "predict_model.init_from_file(os.path.join(output_dir, \"model.pkl\"),\n",
    "                             weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b4oQuFBzN57"
   },
   "outputs": [],
   "source": [
    "def make_roast(img_path, model):\n",
    "\n",
    "  pic, path = load_image(img_path)\n",
    "  pic = tf.expand_dims(pic, 0) \n",
    "  features = image_features_extract_model.predict(pic)\n",
    "  \n",
    "  features = tf.reshape(features,\n",
    "                              (features.shape[0], -1, features.shape[3]))\n",
    "  features = features.numpy()\n",
    "  start = np.array(tokenizer.word_index['<start>'])\n",
    "  end = tokenizer.word_index['<end>']\n",
    "  start = start.reshape((1,1))\n",
    "  \n",
    "  out = model((features, start))\n",
    "  result = [int(out[1])]\n",
    "  for i in range(10):\n",
    "    newIn = np.argmax(out[0][0,:], axis=-1).reshape((1,1))\n",
    "    out = model((features, newIn))\n",
    "    result.append(int(out[1]))\n",
    "  return result\n",
    "\n",
    "path = img_name_train[30]\n",
    "#print(path)\n",
    "pred = make_roast('/content/resizedFinals/resized/69g375.jpg', predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqyE9Yc1luyI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinalNetwork",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
